{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Working Aproach**\n",
    "\n",
    "\n",
    "1.   Convert raw image to HSV format.\n",
    "2.   Remove noise using Gaussian Blur.\n",
    "3.   Run k-means clustering on preprocessed image for color based segmentation.\n",
    "4.   Detect the edges in clustered image.\n",
    "5.   Find contours in Edge Detection output.\n",
    "6.   Generate the bounding Box to get the height/width of Paper and Feet.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Assumptions**\n",
    "\n",
    "\n",
    "\n",
    "1.   Printer Paper is used as a reference (Height/Width is known and White background will help in Preprocessing).\n",
    "2.   Foot should be in center, touching one edge of paper.\n",
    "3.   Floor color should be different than white.\n",
    "4.   Image should be clicked from top angle.\n",
    "5.   Paper should be completely visible in the clicked image.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import ndimage\n",
    "from imutils import contours\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "from sklearn.cluster import KMeans\n",
    "import random as rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mount data path from drive. \n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    img = cv2.GaussianBlur(img, (9, 9), 0)\n",
    "    img = img/255\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImage(img):\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    #plt.title('Clustered Image')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropOrig(bRect, oimg):\n",
    "    # x (Horizontal), y (Vertical Downwards) are start coordinates\n",
    "    # img.shape[0] = height of image\n",
    "    # img.shape[1] = width of image\n",
    "\n",
    "    x,y,w,h = bRect\n",
    "\n",
    "    print(x,y,w,h)\n",
    "    pcropedImg = oimg[y:y+h,x:x+w]\n",
    "\n",
    "    x1, y1, w1, h1 = 0, 0, pcropedImg.shape[1], pcropedImg.shape[0]\n",
    "\n",
    "    y2 = int(h1/10)\n",
    "\n",
    "    x2 = int(w1/10)\n",
    "\n",
    "    crop1 = pcropedImg[y1+y2:h1-y2,x1+x2:w1-x2]\n",
    "\n",
    "    #cv2_imshow(crop1)\n",
    "\n",
    "    ix, iy, iw, ih = x+x2, y+y2, crop1.shape[1], crop1.shape[0]\n",
    "\n",
    "    croppedImg = oimg[iy:iy+ih,ix:ix+iw]\n",
    "\n",
    "    return croppedImg, pcropedImg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlayImage(croppedImg, pcropedImg):\n",
    "\n",
    "\n",
    "    x1, y1, w1, h1 = 0, 0, pcropedImg.shape[1], pcropedImg.shape[0]\n",
    "\n",
    "    y2 = int(h1/10)\n",
    "\n",
    "    x2 = int(w1/10)\n",
    "\n",
    "    new_image = np.zeros((pcropedImg.shape[0], pcropedImg.shape[1], 3), np.uint8)\n",
    "    new_image[:, 0:pcropedImg.shape[1]] = (255, 0, 0) # (B, G, R)\n",
    "\n",
    "    new_image[ y1+y2:y1+y2+croppedImg.shape[0], x1+x2:x1+x2+croppedImg.shape[1]] = croppedImg\n",
    "\n",
    "    return new_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeans_cluster(img):\n",
    "\n",
    "    # For clustering the image using k-means, we first need to convert it into a 2-dimensional array\n",
    "    # (H*W, N) N is channel = 3\n",
    "    image_2D = img.reshape(img.shape[0]*img.shape[1], img.shape[2])\n",
    "\n",
    "    # tweak the cluster size and see what happens to the Output\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0).fit(image_2D)\n",
    "    clustOut = kmeans.cluster_centers_[kmeans.labels_]\n",
    "\n",
    "    # Reshape back the image from 2D to 3D image\n",
    "    clustered_3D = clustOut.reshape(img.shape[0], img.shape[1], img.shape[2])\n",
    "\n",
    "    clusteredImg = np.uint8(clustered_3D*255)\n",
    "\n",
    "    return clusteredImg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBoundingBox(img):\n",
    "\n",
    "    contours, _ = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    #print(len(contours))\n",
    "    contours = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    contours_poly = [None]*len(contours)\n",
    "    boundRect = [None]*len(contours)\n",
    "\n",
    "    for i, c in enumerate(contours):\n",
    "        contours_poly[i] = cv2.approxPolyDP(c, 3, True)\n",
    "        boundRect[i] = cv2.boundingRect(contours_poly[i])\n",
    "\n",
    "    \n",
    "    return boundRect, contours, contours_poly, img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawCnt(bRect, contours, cntPoly, img):\n",
    "\n",
    "    drawing = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)   \n",
    "\n",
    "\n",
    "    paperbb = bRect\n",
    "\n",
    "    for i in range(len(contours)):\n",
    "      color = (rng.randint(0,256), rng.randint(0,256), rng.randint(0,256))\n",
    "      cv2.drawContours(drawing, cntPoly, i, color)\n",
    "      #cv2.rectangle(drawing, (int(boundRect[i][0]), int(boundRect[i][1])), \\\n",
    "              #(int(boundRect[i][0]+boundRect[i][2]), int(boundRect[i][1]+boundRect[i][3])), color, 2)\n",
    "    cv2.rectangle(drawing, (int(paperbb[0]), int(paperbb[1])), \\\n",
    "              (int(paperbb[0]+paperbb[2]), int(paperbb[1]+paperbb[3])), color, 2)\n",
    "    \n",
    "    return drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgeDetection(clusteredImage):\n",
    "  #gray = cv2.cvtColor(hsvImage, cv2.COLOR_BGR2GRAY)\n",
    "  edged1 = cv2.Canny(clusteredImage, 0, 255)\n",
    "  edged = cv2.dilate(edged1, None, iterations=1)\n",
    "  edged = cv2.erode(edged, None, iterations=1)\n",
    "  return edged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oimg = imread('/content/drive/My Drive/data/straiqrtask/barefeet3.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedOimg = preprocess(oimg)\n",
    "plotImage(preprocessedOimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusteredImg = kMeans_cluster(preprocessedOimg)\n",
    "plotImage(clusteredImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgedImg = edgeDetection(clusteredImg)\n",
    "plotImage(edgedImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting paper bounding box\n",
    "\n",
    "boundRect, contours, contours_poly, img = getBoundingBox(edgedImg)\n",
    "pdraw = drawCnt(boundRect[1], contours, contours_poly, img)\n",
    "plotImage(pdraw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "croppedImg, pcropedImg = cropOrig(boundRect[1], clusteredImg)\n",
    "plotImage(croppedImg)\n",
    "plotImage(pcropedImg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
